{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basics\n",
    "\n",
    "## Libraries\n",
    "\n",
    "We load the required libraries.\n",
    "\n",
    "[Numpy](https://numpy.org/doc/stable/) is used for vector and matrix operations.\n",
    "\n",
    "[Pyplot](https://matplotlib.org/2.0.2/api/pyplot_api.html) is a plotting software to draw graphs and display images.\n",
    "\n",
    "PIL loads images from a file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "# Helper functions for visualization purposes\n",
    "from support import plot\n",
    "np.seterr(divide='ignore', invalid='ignore')\n",
    "from IPython.display import display, Math\n",
    "import ipywidgets as widgets\n",
    "import imageio as iio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdisplay = display(\"\", display_id = True)\n",
    "\n",
    "fig, ax = plt.subplots(1)\n",
    "\n",
    "for frame in iio.imiter(\"<video1>\"):\n",
    "    try:\n",
    "        ax.imshow(frame)\n",
    "        hdisplay.update(fig)\n",
    "    except KeyboardInterrupt:\n",
    "        # save image to 'img' variable\n",
    "        img = frame\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensors in numpy (ndarray)\n",
    "\n",
    "Tensors is a super group in which scalars (rank 0 tensor), vectors (rank 1 tensor) and matrices (rank 2 tensors).\n",
    "\n",
    "We specify the dimensions $d_i$ of a rank $n$ tensor by $[d_1, d_2, \\dots, d_n]$.\n",
    "\n",
    "In numpy, these are handled by [ndarrays](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html).\n",
    "\n",
    "For example, in numpy a vector of size [3] is specified by:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat = np.ones([3])\n",
    "plot.plot_tensor(mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A matrix of size $[3,4]$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat = np.ones([3,4])\n",
    "plot.plot_tensor(mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And a tensor of shape $[3,4,2]$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat = np.ones([3,4,2])\n",
    "plot.plot_tensor(mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A tensor can be transposed using the *np.tranpose* function, effectively swapping ranks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat = np.arange(10)\n",
    "mat.shape = (2,5)\n",
    "trans = np.transpose(mat)\n",
    "display(Math(f\"{plot.draw_matrix(mat)} ^T = {plot.draw_matrix(trans)}\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same is possible on higher ranks, specifying which ranks to switch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat = np.arange(4*3*2)\n",
    "mat.shape = (4,3,2)\n",
    "trans = np.transpose(mat, [0,2,1])\n",
    "display(Math(f\"{plot.draw_matrix(mat)} ^{{T_{{0,2,1}}}} = {plot.draw_matrix(trans)}\"))\n",
    "trans = np.transpose(mat, [1,2,0])\n",
    "display(Math(f\"{plot.draw_matrix(mat)} ^{{T_{{1,2,0}}}} = {plot.draw_matrix(trans)}\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Operations on matrixes are specified as elemnt-wise.\n",
    "\n",
    "For example the plus operator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "a = np.array([[0,1,0], [1,1,0]])\n",
    "b = np.array([[1,1,0], [0,1,1]])\n",
    "c = a+b\n",
    "display(Math(f\"{plot.draw_matrix(a)} + {plot.draw_matrix(b)} = {plot.draw_matrix(c)}\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same is true for other operators. \n",
    "\n",
    "**Note that the multiplication operator does not do a matrix multiplication!** (Use *np.matmul* instead.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = a - b\n",
    "display(Math(f\"{plot.draw_matrix(a)} - {plot.draw_matrix(b)} = {plot.draw_matrix(c)}\"))\n",
    "c = a * b\n",
    "display(Math(f\"{plot.draw_matrix(a)} \\\\otimes {plot.draw_matrix(b)} = {plot.draw_matrix(c)}\"))\n",
    "c = a/b\n",
    "display(Math(f\"{plot.draw_matrix(a)} / {plot.draw_matrix(b)} = {plot.draw_matrix(c)}\"))\n",
    "c = a ** b\n",
    "display(Math(f\"{plot.draw_matrix(a)} ^ {{{plot.draw_matrix(b)}}} = {plot.draw_matrix(c)}\"))\n",
    "c = np.matmul(a,np.transpose(b))\n",
    "display(Math(f\"{plot.draw_matrix(a)} \\\\cdot {plot.draw_matrix(np.transpose(b))} = {plot.draw_matrix(c)}\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logical operators are also possible:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = np.logical_and(a, b)\n",
    "display(Math(f\"{plot.draw_matrix(a)} \\land {plot.draw_matrix(b)} = {plot.draw_matrix(c)}\"))\n",
    "c = np.logical_or(a, b)\n",
    "display(Math(f\"{plot.draw_matrix(a)} \\lor {plot.draw_matrix(b)} = {plot.draw_matrix(c)}\"))\n",
    "c = np.logical_xor(a, b)\n",
    "display(Math(f\"{plot.draw_matrix(a)} \\oplus {plot.draw_matrix(b)} = {plot.draw_matrix(c)}\"))\n",
    "c = np.logical_not(a)\n",
    "display(Math(f\"\\lnot {plot.draw_matrix(a)} = {plot.draw_matrix(c)}\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Images in python\n",
    "\n",
    "Load the image and and display it with pyplot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.open(\"images/banana.png\")\n",
    "img = np.asarray(img, dtype=np.ubyte)\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a helper function to display multiple images for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_images(imgs, names = None):\n",
    "    fig, axes = plt.subplots(1, len(imgs))\n",
    "    fig.set_size_inches(len(imgs) * 5, 5)\n",
    "    if not names:\n",
    "        names = [''] * len(imgs)\n",
    "    for img, ax, name in zip(imgs, axes, names):\n",
    "        ax.imshow(img, cmap='grey')\n",
    "        ax.title.set_text(name)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Digitalization\n",
    "\n",
    "An image is stored as a *tensor* of rank $[w,h,c]$, where:\n",
    "- $w$: The width of the image.\n",
    "- $y$: The height of the image.\n",
    "- $c$: The channels of the image, usually in RGB (red, green, blue) and alpha (a).\n",
    "\n",
    "This looks like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.plot_tensor(img[20:26,20:26,0:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "To inspect each channel, we transpose the representation of the image (swap ranks) to get a vector of the three image channels.\n",
    "\n",
    "Values are also converted to floating point values $\\in [0,1]$ to make calculations easier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = img / 255\n",
    "channels = np.transpose(img, (2, 0, 1))\n",
    "R,G,B = channels[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display every channel of the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_images([R,G,B], ['red', 'green', 'blue'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HSV representation\n",
    "\n",
    "There are other representations, like HSV:\n",
    "\n",
    "It uses the *chroma* $C$:\n",
    "$$\n",
    "max = max(R,G,B)\\\\\n",
    "min = min(R,G,B)\\\\\n",
    "C = max -min\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def chroma(R,G,B):\n",
    "    max = np.max([R,G,B], 0)\n",
    "    min = np.min([R,G,B], 0)\n",
    "    return max-min\n",
    "plt.imshow(chroma(R,G,B))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then calculates the hue $H$:\n",
    "$$\n",
    "H' =\\\\\n",
    "H = 60\\deg \\times H'\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R,G,B = channels\n",
    "\n",
    "def hue(R,G,B):\n",
    "    C = chroma(R,G,B)\n",
    "    max = np.max([R,G,B], 0)\n",
    "    HR = np.mod((G-B)/C, 6)\n",
    "    HG = (B-R)/C + 2\n",
    "    HB = (R-G)/C + 4\n",
    "    H = np.where(np.logical_and(R == max, C>0), HR, 0)\n",
    "    H = np.where(np.logical_and(G == max, C>0), HG, H)\n",
    "    H = np.where(np.logical_and(B == max, C>0), HB, H)\n",
    "    return H\n",
    "plt.imshow(hue(R,G,B), vmin = 0, vmax = 6, cmap = 'hsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def value(R,G,B):\n",
    "    return np.max([R,G,B], 0)\n",
    "\n",
    "plt.imshow(value(R,G,B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saturation(R,G,B):\n",
    "    return chroma(R,G,B) / value(R,G,B)\n",
    "\n",
    "plt.imshow(saturation(R,G,B))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_HSV(R,G,B):\n",
    "    return hue(R,G,B), saturation(R,G,B), value(R,G,B)\n",
    "\n",
    "plt.imshow(np.transpose(to_HSV(R,G,B), [1,2,0]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The HSV representation can be calculated by inversing the operations.\n",
    "\n",
    "This is done by using this shorthand taken from [wikipedia](https://de.wikipedia.org/wiki/HSV-Farbraum#:~:text=In%20HSV%20ist%20der%20Farbort,%25%20%3D%20ges%C3%A4ttigte%2C%20reine%20Farbe)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_RGB(H,S,V):\n",
    "    h = np.floor(H)\n",
    "    f = H - h\n",
    "    p = V * (1-S)\n",
    "    q = V * (1 - S * f)\n",
    "    t = V * (1 - S * (1-f))\n",
    "    rgb = np.where(h == 1, [q, V, p], [V,t,p])\n",
    "    rgb = np.where(h == 2, [p, V, t], rgb)\n",
    "    rgb = np.where(h == 3, [p, q, V], rgb)\n",
    "    rgb = np.where(h == 4, [t, p, V], rgb)\n",
    "    rgb = np.where(h == 5, [V,p,q], rgb)\n",
    "    return rgb\n",
    "\n",
    "h,s,v = to_HSV(R,G,B)\n",
    "r,g,b = to_RGB(h,s,v)\n",
    "rec_img = np.transpose([r,g,b], [1,2,0])\n",
    "plt.imshow(rec_img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task:\n",
    "Eperience what happens when manipulating the values in HSV space!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h,s,v = to_HSV(R,G,B)\n",
    "#v = np.full_like(v, 0.5)\n",
    "#s = np.full_like(s, 1)\n",
    "h = (h + 3) % 6\n",
    "#v = np.floor(v*3) / 3\n",
    "#h = np.floor(h*3) / 3\n",
    "r,g,b = to_RGB(h,s,v)\n",
    "rec_img = np.transpose([r,g,b], [1,2,0])\n",
    "plt.imshow(rec_img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are other, similar representations:\n",
    "- HSL: Relative **l**ightness\n",
    "- HSB: **B**rightness\n",
    "- HSI: **I**ntensity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Object Detection\n",
    "## Thresholding\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = chroma(R,G,B)\n",
    "plt.hist(c)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@widgets.interact(x = (0.0, 0.5, 0.02), y = (0.0, 0.5, 0.02))\n",
    "def chroma_cutoff(x = 0.2, y = 0.3):\n",
    "    try:\n",
    "        plt.imshow(np.logical_or (c > x, c < y))\n",
    "        plt.show()\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Erosion and Dilation\n",
    "\n",
    "from skimage.morphology import erosion, dilation, disk\n",
    "\n",
    "def create_mask(x,y,e):\n",
    "    mask = np.logical_or (c > x, c < y)\n",
    "    if e > 0:\n",
    "        mask = erosion(mask, footprint = disk(e))\n",
    "    elif e < 0:\n",
    "        mask = dilation(mask, footprint = disk(-e))\n",
    "    return mask\n",
    "\n",
    "@widgets.interact(x = (0.0, 0.5, 0.02), y = (0.0, 0.5, 0.02), e = (-10, 10, 1))\n",
    "def chroma_cutoff(x = 0.2, y = 0.3, e = 0):\n",
    "    try:\n",
    "        plt.imshow(create_mask(x,y,e))\n",
    "        plt.show()\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bounding Boxes\n",
    "\n",
    "We draw a bounding box by determining the left and right most pixels, same for top and bottom."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@widgets.interact(x = (0.0, 0.5, 0.02), y = (0.0, 0.5, 0.02), e = (-10, 10, 1))\n",
    "def bounding_box(x = 0.2, y = 0.3, e = 0):\n",
    "    mask = create_mask(x,y,e)\n",
    "    fig, (ax1, ax2) = plt.subplots(2)\n",
    "    if np.any(mask):\n",
    "        index_y, index_x = np.where(mask)\n",
    "        lmin = np.min(index_x)\n",
    "        lmax = np.max(index_x)\n",
    "        rmin = np.min(index_y)\n",
    "        rmax = np.max(index_y)\n",
    "        box = plt.Rectangle((lmin,rmin), lmax - lmin, rmax - rmin,linewidth=1,edgecolor='r',facecolor='none')\n",
    "        ax1.imshow(img)\n",
    "        ax1.add_patch(box)\n",
    "        ax2.imshow(mask)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segmentation\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chan Vese"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.segmentation import chan_vese\n",
    "\n",
    "@widgets.interact(mu = (0,2,0.05), lambda1 = (0.5, 2, 0.1), lambda2 = (0.5, 2, 0.1))\n",
    "def plot_chan_vese(mu = 0.25, lambda1 = 1., lambda2=1.):\n",
    "    plt.imshow(chan_vese(G, mu= mu, lambda1 = lambda1, lambda2=lambda2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flooding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.measure import label\n",
    "\n",
    "@widgets.interact(x = (0.0, 0.5, 0.02), y = (0.0, 0.5, 0.02), e = (-10, 10, 1))\n",
    "def bounding_box(x = 0.2, y = 0.3, e = 0):\n",
    "    mask = create_mask(x,y,e)\n",
    "    labels = label(mask)\n",
    "    fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(12,3))\n",
    "    for i in np.unique(labels):\n",
    "        index_y, index_x = np.where(labels == i)\n",
    "        lmin = np.min(index_x)\n",
    "        lmax = np.max(index_x)\n",
    "        rmin = np.min(index_y)\n",
    "        rmax = np.max(index_y)\n",
    "        box = plt.Rectangle((lmin,rmin), lmax - lmin, rmax - rmin,linewidth=1,edgecolor='r',facecolor='none')\n",
    "        ax1.add_patch(box)\n",
    "    ax1.imshow(img)\n",
    "    ax2.imshow(mask)\n",
    "    ax3.imshow(labels, cmap = 'Set1')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gamma correction\n",
    "\n",
    "Light values may be mapped to other ranges, for example by using [gamma correction](https://en.wikipedia.org/wiki/Gamma_correction).\n",
    "\n",
    "It maps all values in a non-linear fashion by exponating with $\\gamma$:\n",
    "$$\n",
    "img_{out} = img^\\gamma\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gamma_cor(img, gamma: float):\n",
    "    return img ** gamma\n",
    "\n",
    "a = gamma_cor(img, 0.5)\n",
    "b = gamma_cor(img, 1)\n",
    "c = gamma_cor(img, 2)\n",
    "\n",
    "show_images([a,b,c], [0.5,1,2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filters\n",
    "\n",
    "\n",
    "We select our grayscale image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = channels[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fourier Transform\n",
    "Images are 2 dimensional signals where $x$ and $y$ are their coordinates in space with $0<x<w$ and $0<y<h$:\n",
    "\n",
    "$$\n",
    "img(x,y)\n",
    "$$\n",
    "\n",
    "Like in 1D signal processing, we can represent this function as frequencies:\n",
    "\n",
    "$$\n",
    "F(\\omega_1, \\omega_2) = \\sum_{x=-\\infty}^\\infty \\sum_{y=-\\infty}^\\infty img(x,y) e ^{-i\\omega_1 x-i\\omega_2 y}\n",
    "$$\n",
    "\n",
    "Since images are *discrete*, the discrete fourier transform (DFT) is used:\n",
    "\n",
    "$$\n",
    "F(p, q) = \\sum_{x=0}^w \\sum_{y=0}^h img(x,y) e ^{-\\frac{i2 \\pi x}{w}-\\frac{i2 \\pi y}{h}}\n",
    "$$\n",
    "\n",
    "More information on:\n",
    "(https://de.mathworks.com/help/images/fourier-transform.html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.fft import fftn, ifftn\n",
    "import skimage\n",
    "ft = fftn(image)\n",
    "reconstr = np.real(ifftn(ft))\n",
    "magnitudes = np.log(np.abs(ft))\n",
    "show_images([image, magnitudes, reconstr], [\"Input\", \"DFT\", \"Reconstruction\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "width = 10\n",
    "rr, cc= skimage.draw.rectangle((width, width), np.array(ft.shape) - (width, width), shape=ft.shape)\n",
    "mask = np.ones(ft.shape, bool)\n",
    "mask[rr, cc] = False\n",
    "plt.imshow(mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Low pass filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_pass = np.copy(ft)\n",
    "low_pass[rr, cc] = 1.\n",
    "reconstr_lp = np.real(ifftn(low_pass))\n",
    "show_images([np.log(np.abs(low_pass)), reconstr_lp])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### High pass filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_pass = np.copy(ft)\n",
    "high_pass[mask] = 1.\n",
    "reconstr_hp = np.abs(np.real(ifftn(high_pass)))\n",
    "show_images([np.log(np.abs(high_pass)), reconstr_hp])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discrete Filters\n",
    "\n",
    "Discrete filtering can also be represented by the **convolution operation**:\n",
    "$$\n",
    "(f * g)[n] = \\sum_{m=-\\infty}^\\infty f[m]g[n - m]\n",
    "$$\n",
    "\n",
    "We declare a function that lets us apply a discrete filter to an grayscale image:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The filter iterates over each position in the matrix:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](https://upload.wikimedia.org/wikipedia/commons/1/19/2D_Convolution_Animation.gif \"Title\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage import convolve\n",
    "\n",
    "mat = np.arange(16)\n",
    "mat.shape = (4,4)\n",
    "filter = np.array([[0,0,1],[0,0,0],[0,0,0]])\n",
    "\n",
    "conv = convolve(mat, filter, mode = \"constant\")\n",
    "\n",
    "display(Math(f\"{plot.draw_matrix(mat)} * {plot.draw_matrix(filter)} = {plot.draw_matrix(conv)}\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filters are cummutative:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_a = np.array([[0,0,1],[0,0,0],[0,0,0]])\n",
    "filter_b = np.array([[0,0,0],[0,0,0],[1,0,0]])\n",
    "\n",
    "both_applied = convolve(convolve(mat, filter_a, mode = 'wrap'), filter_b, mode = 'wrap')\n",
    "\n",
    "display(Math(f\"{plot.draw_matrix(mat)} * {plot.draw_matrix(filter_a)} * {plot.draw_matrix(filter_b)} = {plot.draw_matrix(both_applied)}\"))\n",
    "\n",
    "combined_filter = convolve(filter_a, filter_b, mode='wrap')\n",
    "combined_applied = convolve(mat, combined_filter, mode='wrap')\n",
    "\n",
    "display(Math(f\"{plot.draw_matrix(mat)} * \\\\left( {plot.draw_matrix(filter_a)} * {plot.draw_matrix(filter_b)} \\\\right) = {plot.draw_matrix(mat)} * {plot.draw_matrix(combined_filter)} = {plot.draw_matrix(combined_applied)}\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Edge Detection\n",
    "\n",
    "Edges of an image can be seen as high outputs in their **first-order derivate**.\n",
    "\n",
    "This can be easily calculated using the following filters for the x and y directions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_x = np.array([[0,0,-0],[1,0,-1],[0,0,0]])\n",
    "filter_y = np.transpose(filter_x)\n",
    "\n",
    "plot.plot_tensor(filter_x)\n",
    "plot.plot_tensor(filter_y)\n",
    "\n",
    "show_images([G, convolve(G, filter_x), convolve(G, filter_y)], [\"input\", \"x conv.\", \"y conv.\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the commutative nature of the filters to combine these into the sobel filter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sobel = convolve(filter_x, filter_y, mode='constant')\n",
    "plot.plot_tensor(sobel)\n",
    "filtered = convolve(G, sobel)\n",
    "plt.imshow(filtered, cmap='grey')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By only using the absolute, we receive the strength of each edge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "absolute = np.abs(filtered)\n",
    "plt.imshow(absolute, cmap='grey')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By threshholding we only keep the significant edges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = absolute > 0.1\n",
    "plt.imshow(threshold, cmap='grey')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can look at various thresholds for our image.\n",
    "\n",
    "Often, the ideal threshold value depends on the image and task at hand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = []\n",
    "for t in [0.05,0.1,0.2,0.3,0.4]:\n",
    "    imgs.append(absolute > t)\n",
    "show_images(imgs, [0.05,0.1,0.2,0.3,0.4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are various pre-existing edge filters.\n",
    "\n",
    "For example, the **laplace** filter uses this kernel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "laplace = np.array([[0, -1, 0],[-1,4,-1],[0,-1,0]])\n",
    "plot.plot_tensor(laplace)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is also the *canny edge filter* that has an additional step, only keeping edges that belong to a line:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.feature import canny\n",
    "\n",
    "show_images([np.abs(convolve(G, sobel)), np.abs(convolve(G, laplace)), canny(G)], [\"sobel\", \"laplace\", \"canny\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.filters import gaussian, median\n",
    "from skimage.morphology import disk\n",
    "\n",
    "med = median(image, footprint=disk(20))\n",
    "gauss = gaussian(image, 6.)\n",
    "\n",
    "show_images([image, med, gauss], [\"input\", \"median\", \"gaussian\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task: Comic filter\n",
    "\n",
    "Use the known filters and conversions to make a comic-like filter!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.filters import median\n",
    "from skimage.morphology import disk\n",
    "h,s,v = to_HSV(R,G,B)\n",
    "\n",
    "v = median(v, footprint = disk(10))\n",
    "h = median(h, footprint = disk(10))\n",
    "v = np.floor(v*3) / 3\n",
    "h = np.floor(h*3) / 3\n",
    "s = s* 2\n",
    "edges = np.logical_and(np.abs(convolve(v, sobel)) < 0.4, np.abs(convolve(s, sobel)) < 0.32)\n",
    "v = np.where(edges, v, 0.)\n",
    "r,g,b = to_RGB(h,s,v)\n",
    "\n",
    "\n",
    "rec_img = np.transpose([r,g,b], [1,2,0])\n",
    "\n",
    "plt.imshow(rec_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.filters import hessian\n",
    "\n",
    "texture = np.asarray(Image.open(\"images/texture.png\"), np.uint8)\n",
    "gray = np.mean(texture, -1)\n",
    "show_images([gray, hessian(gray, sigmas = range(5,6,1))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frangi filter\n",
    "\n",
    "The Frangi filter (https://link.springer.com/chapter/10.1007/BFb0056195#editor-information)[Frangi, A.F., Niessen, W.J., Vincken, K.L., Viergever, M.A. (1998). Multiscale vessel enhancement filtering. In: Wells, W.M., Colchester, A., Delp, S. (eds) Medical Image Computing and Computer-Assisted Intervention — MICCAI’98. MICCAI 1998. Lecture Notes in Computer Science, vol 1496. Springer, Berlin, Heidelberg. https://doi.org/10.1007/BFb0056195]\n",
    "uses the hessian filter to search for tube-like structures. This is useful to find structural features like crags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.filters import frangi, sobel\n",
    "\n",
    "show_images([gray, frangi(gray, sigmas = range(5,6,1)), sobel(gray)], [\"input\", \"frangi\", \"sobel\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hough Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.transform import probabilistic_hough_line\n",
    "from skimage.feature import canny\n",
    "\n",
    "\n",
    "edges = canny(channels[1] * 255, 5, 1, 25)\n",
    "lines = probabilistic_hough_line(edges, threshold=10, line_length=5, line_gap=3)\n",
    "\n",
    "# Generating figure 2\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5), sharex=True, sharey=True)\n",
    "ax = axes.ravel()\n",
    "\n",
    "ax[0].imshow(channels[1], cmap=\"gray\")\n",
    "ax[0].set_title('Input image')\n",
    "\n",
    "ax[1].imshow(edges, cmap=\"gray\")\n",
    "ax[1].set_title('Canny edges')\n",
    "\n",
    "ax[2].imshow(edges * 0)\n",
    "for line in lines:\n",
    "    p0, p1 = line\n",
    "    ax[2].plot((p0[0], p1[0]), (p0[1], p1[1]))\n",
    "ax[2].set_xlim((0, channels[1].shape[1]))\n",
    "ax[2].set_ylim((channels[1].shape[0], 0))\n",
    "ax[2].set_title('Probabilistic Hough')\n",
    "\n",
    "for a in ax:\n",
    "    a.set_axis_off()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
